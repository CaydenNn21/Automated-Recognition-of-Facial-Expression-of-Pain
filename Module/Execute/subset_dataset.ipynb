{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relation between the VAS and PSPI, use this as reference to classify the PSPI to 5 differenct classes\n",
    "https://www.researchgate.net/publication/297637563_Supplemental_Material_Automatic_Pain_Assessment_with_Facial_Activity_Descriptors \n",
    "\n",
    "{PSPI: 0: No Pain; \n",
    "1: Mild Pain (VAS: 1-2); \n",
    "2-3: Moderate (VAS: 5-3);\n",
    "4: Very Pain (VAS: 6-7);\n",
    "\\>=5: Severe Pain (VAS: 8-10)}\n",
    "\n",
    "Proposed size of dataset is 6000 images \n",
    "each class should contains 1200 images\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "def get_subject_list():\n",
    "\tdataset_root = \"D:\\\\Library\\Documents\\\\UM Lecture Notes & Tutorial\\\\FYP\\\\Dataset\\\\UNBC-McMaster Shoulder Pain Data\"\n",
    "\timg_folder_dir = os.path.join(dataset_root, \"Images\")\n",
    "\treturn list(os.listdir(img_folder_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "dataset_root = \"D:\\\\Library\\Documents\\\\UM Lecture Notes & Tutorial\\\\FYP\\\\Dataset\\\\UNBC-McMaster Shoulder Pain Data\"\n",
    "img_folder_dir = os.path.join(dataset_root, \"Images\")\n",
    "PSPI_folder_dir = os.path.join(dataset_root, \"Frame_Labels\", \"PSPI\")\n",
    "\n",
    "# Get all subject \n",
    "all_subject = get_subject_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 1201, 1: 0, 2: 0, 3: 0, 4: 0}\n",
      "next\n",
      "{0: 1201, 1: 838, 2: 0, 3: 0, 4: 0}\n",
      "continue\n",
      "{0: 1201, 1: 1201, 2: 0, 3: 0, 4: 0}\n",
      "next\n",
      "{0: 1201, 1: 1201, 2: 984, 3: 0, 4: 0}\n",
      "continue\n",
      "{0: 1201, 1: 1201, 2: 1201, 3: 0, 4: 0}\n",
      "next\n",
      "{0: 1201, 1: 1201, 2: 1201, 3: 508, 4: 0}\n",
      "continue\n",
      "{0: 1201, 1: 1201, 2: 1201, 3: 619, 4: 0}\n",
      "continue\n",
      "{0: 1201, 1: 1201, 2: 1201, 3: 668, 4: 0}\n",
      "continue\n",
      "{0: 1201, 1: 1201, 2: 1201, 3: 717, 4: 0}\n",
      "continue\n",
      "{0: 1201, 1: 1201, 2: 1201, 3: 766, 4: 0}\n",
      "continue\n",
      "{0: 1201, 1: 1201, 2: 1201, 3: 802, 4: 0}\n",
      "continue\n",
      "{0: 1201, 1: 1201, 2: 1201, 3: 802, 4: 0}\n",
      "next\n",
      "{0: 1201, 1: 1201, 2: 1201, 3: 802, 4: 550}\n",
      "continue\n",
      "{0: 1201, 1: 1201, 2: 1201, 3: 802, 4: 788}\n",
      "continue\n",
      "{0: 1201, 1: 1201, 2: 1201, 3: 802, 4: 895}\n",
      "continue\n"
     ]
    }
   ],
   "source": [
    "from time import sleep\n",
    "from tqdm.notebook import trange\n",
    "import os \n",
    "subset_image_dir = {}\n",
    "subset_label= {}\n",
    "class_count = {x:0 for x in range(5)}\n",
    "read_file = {}\n",
    "\n",
    "dataset_root = \"D:\\\\Library\\Documents\\\\UM Lecture Notes & Tutorial\\\\FYP\\\\Dataset\\\\UNBC-McMaster Shoulder Pain Data\"\n",
    "img_folder_dir = os.path.join(dataset_root, \"Images\")\n",
    "PSPI_folder_dir = os.path.join(dataset_root, \"Frame_Labels\", \"PSPI\")\n",
    "subject_id = os.listdir(img_folder_dir)\n",
    "classID = 0\n",
    "\n",
    "while True:\n",
    "\tcount = class_count.get(classID)\n",
    "\tfor subject in subject_id:\n",
    "\t\ttemp = {}\n",
    "\t\tPSPI_sequence_dir = os.path.join(PSPI_folder_dir, subject)\n",
    "\t\ti = 0\n",
    "\t\tfor sequence_id in os.listdir(PSPI_sequence_dir):\n",
    "\t\t\tPSPI_sequence_id_folder = os.path.join(PSPI_sequence_dir, sequence_id)\n",
    "\t\t\ttemp_img_dir_list =[]\n",
    "\t\t\ttemp_label_list = []\n",
    "\t\t\tfor frames in os.listdir(PSPI_sequence_id_folder):\n",
    "\t\t\t\tif i<=48 and count<=1200:\n",
    "\t\t\t\t\tpain_intensity = 0\n",
    "\t\t\t\t\twith open(os.path.join(PSPI_sequence_id_folder, frames), 'r') as label_file:\n",
    "\t\t\t\t\t\tpain_intensity = int(float(label_file.read().strip()))\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\tappend_flag = read_file.get(os.path.join(PSPI_sequence_id_folder, frames))\n",
    "\t\t\t\t\tif ((pain_intensity <=1 and classID == pain_intensity) or (pain_intensity == 4 and classID == 3)) and append_flag is None:\n",
    "\t\t\t\t\t\ttemp_img_dir_list.append(os.path.join(img_folder_dir,subject, sequence_id, frames))\n",
    "\t\t\t\t\t\ttemp_label_list.append(os.path.join(PSPI_sequence_id_folder, frames))\n",
    "\t\t\t\t\t\tread_file[os.path.join(PSPI_sequence_id_folder, frames)] = False\n",
    "\t\t\t\t\t\ti+=1\n",
    "\t\t\t\t\t\tcount+=1\n",
    "\t\t\t\t\telif (pain_intensity==2 or pain_intensity==3) and classID==2 and append_flag is None:\n",
    "\t\t\t\t\t\ttemp_img_dir_list.append(os.path.join(img_folder_dir,subject, sequence_id, frames))\n",
    "\t\t\t\t\t\ttemp_label_list.append(os.path.join(PSPI_sequence_id_folder, frames))\n",
    "\t\t\t\t\t\tread_file[os.path.join(PSPI_sequence_id_folder, frames)] = False\n",
    "\t\t\t\t\t\ti+=1\n",
    "\t\t\t\t\t\tcount+=1\n",
    "\t\t\t\t\telif pain_intensity>=5 and classID == 4 and append_flag is None:\n",
    "\t\t\t\t\t\ttemp_img_dir_list.append(os.path.join(img_folder_dir,subject, sequence_id, frames))\n",
    "\t\t\t\t\t\ttemp_label_list.append(os.path.join(PSPI_sequence_id_folder, frames))\n",
    "\t\t\t\t\t\tread_file[os.path.join(PSPI_sequence_id_folder, frames)] = False\n",
    "\t\t\t\t\t\ti+=1\n",
    "\t\t\t\t\t\tcount+=1\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tbreak\n",
    "\t\t\tif subset_image_dir.get(subject) is None:\n",
    "\t\t\t\tsubset_image_dir[subject] = temp_img_dir_list\n",
    "\t\t\t\tsubset_label[subject] = temp_label_list\n",
    "\t\t\telse:\n",
    "\t\t\t\tupdate_img_list = subset_image_dir.get(subject)\n",
    "\t\t\t\tupdate_img_list.extend(temp_img_dir_list)\n",
    "\t\t\t\tsubset_image_dir.update({subject:(update_img_list)})\n",
    "\n",
    "\t\t\t\tupdate_label_list = subset_label.get(subject)\n",
    "\t\t\t\tupdate_label_list.extend(temp_label_list)\n",
    "\t\t\t\tsubset_label.update({subject:(update_label_list)})\n",
    "\t\t\tif i == 49 or count>=1200:\n",
    "\t\t\t\tbreak\n",
    "\t\t\n",
    "\n",
    "\tif count<1200 and not count==class_count.get(classID):\n",
    "\t\tclass_count.update({classID:count})\n",
    "\t\tprint(class_count)\n",
    "\t\tprint(\"continue\")\n",
    "\t\tcontinue\n",
    "\telif classID < 4 :\n",
    "\t\tclass_count.update({classID:count})\n",
    "\t\tprint(class_count)\n",
    "\t\tprint(\"next\")\n",
    "\t\tclassID+=1\n",
    "\telse:\n",
    "\t\tbreak\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the path of the image and respective label file into the csv file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "def write_subject(subject, data_list, label_list):\n",
    "\twith open('subset_list.csv', 'a', encoding='UTF8',newline='') as f:\n",
    "\t\twriter = csv.writer(f)\n",
    "\t\tfor i in range(len(data_list)):\n",
    "\t\t\twriter.writerow([subject, (data_list[i].split(\"_\")[0] + \".png\").replace(\"Images\",\"Preprocessed\"), label_list[i]])\n",
    "\n",
    "def reset_csv():\n",
    "\twith open('subset_list.csv', 'w', encoding='UTF8',newline='') as f:\n",
    "\t\twriter = csv.writer(f)\n",
    "\t\twriter.writerow([\"subject\", \"path\", \"label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write lines "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subject in subset_image_dir.keys():\n",
    "\twrite_subject(subject, subset_image_dir.get(subject), subset_label.get(subject))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moves all the selected data into another subset folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import csv\n",
    "\n",
    "image_dest = \"D:\\\\Library\\\\Documents\\\\UM Lecture Notes & Tutorial\\\\FYP\\\\Dataset\\\\subset\\\\Images\"\n",
    "label_dest = \"D:\\\\Library\\\\Documents\\\\UM Lecture Notes & Tutorial\\\\FYP\\\\Dataset\\\\subset\\\\Labels\"\n",
    "\n",
    "with open (\"subset_list.csv\") as csv_file:\n",
    "\tcsv_reader = csv.reader(csv_file, delimiter=',')\n",
    "\tnext(csv_reader)\n",
    "\n",
    "\tfor row in csv_reader:\n",
    "\t\tif not os.path.exists(os.path.join(image_dest, row[0])):\n",
    "\t\t\tos.mkdir(os.path.join(image_dest, row[0]))\n",
    "\t\t\tos.mkdir(os.path.join(label_dest, row[0]))\n",
    "\n",
    "\t\tshutil.copy(row[1], os.path.join(image_dest, row[0]))\n",
    "\t\tshutil.copy(row[2], os.path.join(label_dest, row[0]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
