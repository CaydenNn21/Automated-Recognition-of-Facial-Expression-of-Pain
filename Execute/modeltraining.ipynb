{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install face-alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import math\n",
    "from face_alignment import FaceAlignment\n",
    "from face_alignment import LandmarksType\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "import torch\n",
    "from torchvision.transforms import functional as TF\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data analysis\n",
    "\n",
    "- Show the number of frames contained in each sequence\n",
    "\n",
    "- Show the sequence frames along with the Prkachin and Solomon Pain Intensity (PSPI) score of each frame in a graph\n",
    "\n",
    "- Show the number of the sequence that are labeled as no pain, medium pain and severe pain in a histogram\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import make_interp_spline\n",
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = \"D:\\\\Library\\\\Documents\\\\UM Lecture Notes & Tutorial\\\\FYP\\\\Dataset\\\\UNBC-McMaster Shoulder Pain Data\"\n",
    "\n",
    "if os.path.exists(data_root):\n",
    "    print(\"Path is found.\",sep=' ', end=' ', flush=True)\n",
    "    if os.scandir(data_root):\n",
    "        print(\"Folder is not empty.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory where your data is stored\n",
    "img_dir = os.path.join(data_root, \"Images\")\n",
    "images = os.listdir(img_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The total count of the PSPI from 0 - 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PSPI_label = data_root + '\\\\Frame_Labels\\\\PSPI'\n",
    "\n",
    "label_count = {}\n",
    "\n",
    "for subject in os.listdir(PSPI_label):\n",
    "    for sequence in os.listdir(os.path.join(PSPI_label, subject)):\n",
    "        for label in os.listdir(os.path.join(PSPI_label,subject, sequence)):\n",
    "            with open(os.path.join(PSPI_label,subject, sequence, label), 'r') as label_file:\n",
    "                vas = int(float(label_file.read().strip()))\n",
    "                if label_count.get(vas) is None:\n",
    "                    label_count[vas] = 1\n",
    "                else:\n",
    "                    temp = label_count.get(vas)\n",
    "                    #update count value\n",
    "                    label_count[vas] += 1\n",
    "\n",
    "print(label_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract labels and counts from the dictionary\n",
    "sorted_label_counts = dict(sorted(label_count.items()))\n",
    "\n",
    "labels = list(sorted_label_counts.keys())\n",
    "counts = list(sorted_label_counts.values())\n",
    "\n",
    "# Create a bar plot (histogram)\n",
    "plt.bar(labels, counts,tick_label=labels)\n",
    "\n",
    "# Adding labels and title\n",
    "plt.xlabel('Labels')\n",
    "plt.ylabel('Counts')\n",
    "plt.title('PSPI Label Counts Histogram')\n",
    "\n",
    "# # Display the plot\n",
    "plt.tight_layout()\n",
    "\n",
    "for x, y in zip(labels, counts):\n",
    "    plt.annotate(f'{y}', (x, y), textcoords=\"offset points\", xytext=(0, 100), ha='center')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Frames vs PSPI Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.layout_engine import ConstrainedLayoutEngine\n",
    "def print_img_PSPI(img_dir, subject, sequence):\n",
    "    image_filenames = []\n",
    "    pain_intensity_labels = []\n",
    "    average_intensity_scores = []\n",
    "\n",
    "    sequence_dir = os.path.join(img_dir, subject , sequence)\n",
    "    image_label_dir = os.path.join(data_root, \"Frame_Labels\",\"PSPI\", subject, sequence)\n",
    "\n",
    "    for filename in sorted(os.listdir(sequence_dir)):\n",
    "        if filename.endswith('.png'):  # Adjust the file extension as needed\n",
    "            # Load the image\n",
    "            img = cv2.imread(os.path.join(sequence_dir, filename))\n",
    "            image_filenames.append(img)\n",
    "\n",
    "            # Load the pain intensity label from the corresponding text file\n",
    "            label_filename = os.path.splitext(filename)[0] + '_facs.txt'\n",
    "\n",
    "            with open(os.path.join(image_label_dir, label_filename), 'r') as label_file:\n",
    "                pain_intensity = int(float(label_file.read().strip()))\n",
    "                pain_intensity_labels.append(pain_intensity)\n",
    "\n",
    "   # Calculate average intensity scores for each batch (for demonstration purposes)\n",
    "    num_batches = 15\n",
    "    batch_size = len(image_filenames) // num_batches\n",
    "\n",
    "\n",
    "    for batch_index in range(num_batches):\n",
    "        start_index = batch_index * batch_size\n",
    "        end_index = start_index + batch_size\n",
    "\n",
    "\n",
    "        # Calculate the average intensity score for the current batch\n",
    "        average_intensity = np.mean(pain_intensity_labels[start_index:end_index])\n",
    "        average_intensity_scores.append(pain_intensity_labels[start_index])\n",
    "\n",
    "    # Create a smooth curve fitted graph\n",
    "    x = np.arange(0, num_batches)\n",
    "    y = average_intensity_scores\n",
    "\n",
    "    # Use make_interp_spline for a smooth curve fit\n",
    "    x_smooth = np.linspace(x.min(), x.max(), 300)\n",
    "    y_smooth = make_interp_spline(x, y, k=3)(x_smooth)\n",
    "\n",
    "    fig = plt.figure(figsize=(16, 10),constrained_layout= True)\n",
    "\n",
    "    gs1 = fig.add_gridspec(2, num_batches,height_ratios=[1,3])\n",
    "\n",
    "    # Create subplots for the images in the first row\n",
    "    for i in range(num_batches):\n",
    "        ax = fig.add_subplot(gs1[0, i])\n",
    "        ax.imshow(cv2.cvtColor(image_filenames[i * batch_size], cv2.COLOR_BGR2RGB))\n",
    "        ax.axis('off')\n",
    "\n",
    "    # Plot the smooth curve in the second row\n",
    "    ax = fig.add_subplot(gs1[1, :num_batches])\n",
    "    ax.plot(x_smooth, y_smooth, label='Smooth Curve', linewidth=2)\n",
    "    ax.scatter(x, y, color='red', marker='o', label='Data Points')\n",
    "    ax.set_xlabel('Batch Index')\n",
    "    ax.set_ylabel('Average Pain Intensity')\n",
    "    ax.set_title('Smooth Curve Fitted Graph - ' + sequence)\n",
    "    ax.legend()\n",
    "    ax.grid(True)\n",
    "\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store image filenames and pain intensity labels\n",
    "for subject in images:\n",
    "    for sequence in os.listdir(img_dir+'/'+subject):\n",
    "        print_img_PSPI(img_dir, subject, sequence)\n",
    "\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess the data\n",
    "- enhance the appearance of the face\n",
    "- align the face\n",
    "- crop the face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import trange, tqdm_notebook\n",
    "from time import sleep \n",
    "\n",
    "class preprocess():\n",
    "\n",
    "    def __init__(self, frames, subject_code, sequence_code):\n",
    "        super(preprocess, self).__init__()\n",
    "        self.frames = frames\n",
    "        self.subject_code = subject_code\n",
    "        self.sequence_code = sequence_code\n",
    "        # Do landmark detection on the input frames for face recognition proposes\n",
    "        # self.landmarkDetection()\n",
    "\n",
    "        self.readLandmarkLabel()\n",
    "\n",
    "        # Mask the non-face area with black pixels\n",
    "        self.frames = self.maskFace()\n",
    "\n",
    "        # Tilt and align the face at centre, then crop the frames according to the face region\n",
    "        self.frames = self.tiltAlign()\n",
    "\n",
    "        self.frames = self.resize_frames()\n",
    "\n",
    "        self.savePreprocessedimages()\n",
    "\n",
    "    def resize_frames(self):\n",
    "        frames = []\n",
    "\n",
    "        for img in self.frames:\n",
    "            img = cv.resize(img, (120,120))\n",
    "            frames.append(img)\n",
    "\n",
    "        return frames\n",
    "    def savePreprocessedimages(self):\n",
    "        print(\"Saving...\")\n",
    "        path = \"D:\\\\Library\\\\Documents\\\\UM Lecture Notes & Tutorial\\\\FYP\\\\Dataset\\\\Preprocessed\"\n",
    "        target_dir =\"\"\n",
    "        # check filepath exist\n",
    "        if not os.path.exists(path):\n",
    "            print(\"checking root...\")\n",
    "            os.mkdir(path)\n",
    "            \n",
    "        subject_path = os.path.join(path, self.subject_code)\n",
    "\n",
    "        if not os.path.exists(subject_path):\n",
    "            print(\"checking subject folder\")\n",
    "            os.mkdir(subject_path)\n",
    "\n",
    "        sequence_path = os.path.join(subject_path, self.sequence_code)\n",
    "\n",
    "        if not os.path.exists(sequence_path):\n",
    "            print(\"checking sequence path\")\n",
    "            os.mkdir(sequence_path)\n",
    "            target_dir = sequence_path\n",
    "\n",
    "        print(target_dir)\n",
    "        for i in trange((len(self.frames)), desc=\"Saving_\" +self.sequence_code ):\n",
    "            n = f'{i+1:03}'\n",
    "            cv.imwrite(f'{target_dir}\\{self.sequence_code}{n}.png', cv.cvtColor(self.frames[i], cv.COLOR_BGR2RGB))\n",
    "            sleep(0.01)\n",
    "\n",
    "    def readLandmarkLabel(self):\n",
    "        label_path = os.path.join(data_root, \"AAM_landmarks\", self.subject_code, self.sequence_code)\n",
    "        all_frames_landmark = []\n",
    "        frames = self.frames\n",
    "        n=0\n",
    "        for frames_label in os.listdir(label_path):\n",
    "            \n",
    "            landmarks = []\n",
    "            landmarks_tuple = []\n",
    "\n",
    "            img = (frames[n])\n",
    "            img = img.copy()\n",
    "            \n",
    "            if frames_label.endswith(\".txt\"):\n",
    "                landmark_file_path = os.path.join(label_path, frames_label)\n",
    "\n",
    "                with open(landmark_file_path,  'r') as file:\n",
    "                    landmarks = [list(map(float, line.strip().split())) for line in file]\n",
    "\n",
    "            if landmarks is not None:\n",
    "                # Iterate over the detected faces\n",
    "                for pred in landmarks:\n",
    "                    \n",
    "                    x, y = pred\n",
    "                    landmarks_tuple.append((int(x), int(y)))\n",
    "                    if 0 <= x < img.shape[1] and 0 <= y < img.shape[0]:\n",
    "                        cv.circle(img, (int(x), int(y)), 2, (0, 255, 0), -1)\n",
    "            all_frames_landmark.append(landmarks_tuple)\n",
    "            n += 1\n",
    "\n",
    "        self.framesLandmark=all_frames_landmark\n",
    "\n",
    "    def delete_files_in_directory(self, directory_path):\n",
    "        try:\n",
    "            with os.scandir(directory_path) as entries:\n",
    "                for entry in entries:\n",
    "                    if entry.is_file():\n",
    "                        os.unlink(entry.path)\n",
    "                print(\"All files deleted successfully.\")\n",
    "        except OSError:\n",
    "            print(\"Error occurred while deleting files.\")\n",
    "\n",
    "    def landmarkDetection(self):\n",
    "        print(\"Detecting landmark...\")\n",
    "        frames = self.frames\n",
    "        output = []\n",
    "        framesLandmark = []\n",
    "        model = FaceAlignment(landmarks_type=LandmarksType.TWO_D, face_detector='blazeface',\n",
    "                              face_detector_kwargs={'back_model': True}, device='cpu')\n",
    "        \n",
    "        for n in trange(len(frames), desc=\"Detecting landmark_\" + self.sequence_code):\n",
    "            img = (frames[n])\n",
    "            img = img.copy()\n",
    "            landmarks = model.get_landmarks(img)\n",
    "            landmarks_tuple = []\n",
    "            if landmarks is not None:\n",
    "                # Iterate over the detected faces\n",
    "                for pred in landmarks:\n",
    "                    # Draw landmarks on the frame\n",
    "                    for point in pred:\n",
    "                        x, y = point\n",
    "                        landmarks_tuple.append((int(x), int(y)))\n",
    "                        if 0 <= x < img.shape[1] and 0 <= y < img.shape[0]:\n",
    "                            cv.circle(img, (int(x), int(y)), 2, (0, 255, 0), -1)\n",
    "\n",
    "            framesLandmark.append(landmarks_tuple)\n",
    "            output.append(img)\n",
    "            sleep(0.01)\n",
    "\n",
    "        self.framesLandmark = framesLandmark\n",
    "\n",
    "    def tiltAlign(self):\n",
    "        print(\"Tilting and aligning...\")\n",
    "        frames = self.frames\n",
    "        output =[]\n",
    "        for i in trange(len(frames), desc = \"Tilt_align_\" + self.sequence_code):\n",
    "            \n",
    "            img = frames[i]\n",
    "            landmarkTuple = self.framesLandmark[i]\n",
    "            # Landmark index of reight eye and left eye are\n",
    "            right_eye_cood = [(landmarkTuple[39][0] + landmarkTuple[36][0])/2, (landmarkTuple[39][1] + landmarkTuple[36][1])/2]\n",
    "            left_eye_cood = [(landmarkTuple[45][0] + landmarkTuple[42][0])/2, (landmarkTuple[45][1] + landmarkTuple[42][1])/2]\n",
    "            x1, y1 = right_eye_cood\n",
    "            x2, y2 = left_eye_cood\n",
    "\n",
    "            a = abs(y1 - y2)\n",
    "            b = abs(x2 - x1)\n",
    "            c = math.sqrt(a * a + b * b)\n",
    "\n",
    "            cos_alpha = (b * b + c * c - a * a) / (2 * b * c)\n",
    "\n",
    "            alpha = np.arccos(cos_alpha)\n",
    "            alpha = (alpha * 180) / math.pi\n",
    "            img = Image.fromarray(img)\n",
    "            if y1>y2 :\n",
    "                alpha = -alpha\n",
    "            img = np.array(img.rotate(alpha))\n",
    "            plt.imshow(cv.cvtColor(img, cv.COLOR_BGR2RGB))\n",
    "            output.append(img)\n",
    "            \n",
    "            sleep(0.01)\n",
    "        return output\n",
    "\n",
    "    def maskFace(self):\n",
    "        print(\"Masking...\")\n",
    "        routes = [i for i in range (16,-1,-1)] + [i for i in range (17,26+1)]\n",
    "\n",
    "        frames = self.frames\n",
    "        output = []\n",
    "        for n in trange(len(frames), desc = \"Masking_\" + self.sequence_code):\n",
    "            \n",
    "            routes_cod = []\n",
    "            mask = None\n",
    "            out = None\n",
    "            landmarks_tuple = self.framesLandmark[n]\n",
    "            img = (frames[n])\n",
    "            img = img.copy()\n",
    "            img2 = img.copy()\n",
    "            for i in range (0, len(routes)-1):\n",
    "                source_point = routes[i]\n",
    "                target_point = routes[i+1]\n",
    "\n",
    "                source_cod = landmarks_tuple[source_point]\n",
    "                target_cod = landmarks_tuple[target_point]\n",
    "                routes_cod.append(source_cod)\n",
    "                cv.line(img, (source_cod), (target_cod),(255,255,255),2)\n",
    "\n",
    "            routes_cod = routes_cod+[routes_cod[0]]\n",
    "\n",
    "            mask = np.zeros((img.shape[0], img.shape[1]))\n",
    "            mask = cv.fillConvexPoly(mask, np.array(routes_cod),1)\n",
    "            mask = mask.astype(np.bool_)\n",
    "            out = np.zeros_like(img)\n",
    "            out[mask] = img2[mask]\n",
    "            # plt.imshow(cv.cvtColor(out, cv.COLOR_BGR2RGB))\n",
    "            output.append(cv.cvtColor(self.cropFaceArea(out, mask), cv.COLOR_BGR2RGB))\n",
    "            \n",
    "            sleep(0.01)\n",
    "        return output\n",
    "\n",
    "    def cropFaceArea(self, frame, mask):\n",
    "\n",
    "        gray = cv.cvtColor(frame,cv.COLOR_BGR2GRAY)\n",
    "        contours, _ = cv.findContours(gray, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        # Get the bounding box of the largest contour\n",
    "\n",
    "        largest_contour = max(contours, key=cv.contourArea)\n",
    "        x, y, w, h = cv.boundingRect(largest_contour)\n",
    "\n",
    "        # Crop the image to the size of the masked face\n",
    "        cropped_image = frame[y:y+h, x:x+w]\n",
    "\n",
    "        return cropped_image\n",
    "\n",
    "    def padding_normalization(self, target_length):\n",
    "        print(\"padding and normalising...\")\n",
    "        \"\"\"\n",
    "        Preprocesses a sequence of images and pads them to a target length.\n",
    "\n",
    "        Args:\n",
    "            images (list): List of PIL images.\n",
    "            target_length (int): Desired length of the sequence after padding.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Tensor of preprocessed and padded images.\n",
    "        \"\"\"\n",
    "        # Resize the images to a consistent size\n",
    "        array_images = self.frames\n",
    "        images =[]\n",
    "\n",
    "        for image in array_images:\n",
    "            images.append((Image.fromarray(image)))\n",
    "\n",
    "        resized_images = [TF.resize((img), [224, 224]) for img in images]\n",
    "\n",
    "        # Convert the images to tensors\n",
    "        tensor_images = [TF.to_tensor(img) for img in resized_images]\n",
    "\n",
    "        # Stack the tensor images along a new dimension (sequence dimension)\n",
    "        tensor_sequence = torch.stack(tensor_images)\n",
    "\n",
    "        # Calculate the current length of the sequence\n",
    "        current_length = tensor_sequence.size(0)\n",
    "\n",
    "        # Pad the sequence if necessary\n",
    "        if current_length < target_length:\n",
    "            padding_length = target_length - current_length\n",
    "            padding = torch.zeros(padding_length, *tensor_sequence.shape[1:])\n",
    "            tensor_sequence = torch.cat((tensor_sequence, padding))\n",
    "\n",
    "        # Normalize the tensor sequence\n",
    "        # Define the mean and standard deviation values for normalization\n",
    "        mean = [0.485, 0.456, 0.406]\n",
    "        std = [0.229, 0.224, 0.225]\n",
    "\n",
    "        # Apply normalization to the tensor sequence\n",
    "        normalize = transforms.Normalize(mean=mean, std=std)\n",
    "        normalized_sequence = normalize(tensor_sequence)\n",
    "\n",
    "        return normalized_sequence\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import trange\n",
    "from tqdm.notebook import trange, tqdm\n",
    "\n",
    "from time import sleep \n",
    "\n",
    "# Load the images into a array\n",
    "# The structure of the dataset folder\n",
    "# root > Images > Subject > Sequences > *frame\n",
    "\n",
    "\n",
    "images_data_dir = img_dir # Path that contains all the subject frames of sequences\n",
    "labels_dir = os.path.join(data_root, 'Sequence_Labels', \"VAS\")\n",
    "\n",
    "# Create lists to store preprocessed images and labels\n",
    "preprocessed_images = []\n",
    "preprocessed_labels = []\n",
    "\n",
    "image_subject = os.listdir(images_data_dir)\n",
    "\n",
    "# Iterate through subject folders (assuming subject folders are labeled with integers)\n",
    "for i in trange(len(image_subject), desc = \"Preprocess progress\" ) :\n",
    "    subject_folder = image_subject[i]\n",
    "    subject_path = os.path.join(images_data_dir, subject_folder)\n",
    "\n",
    "    # Skip non-directory files\n",
    "    if not os.path.isdir(subject_path):\n",
    "        continue\n",
    "\n",
    "    # Iterate through sequence folders\n",
    "    all_sequence_list = os.listdir(subject_path)\n",
    "    for i in trange(len(all_sequence_list), desc = \"Subject_\"+subject_folder):\n",
    "        \n",
    "        sequence_folder = all_sequence_list[i]\n",
    "        if os.path.exists(os.path.join(\"D:\\\\Library\\\\Documents\\\\UM Lecture Notes & Tutorial\\\\FYP\\\\Dataset\\\\Preprocessed\",\n",
    "                                       subject_folder, sequence_folder)):\n",
    "            continue\n",
    "        sequence_path = os.path.join(subject_path, sequence_folder)\n",
    "\n",
    "        # Initialize a list to store image frames in the current sequence\n",
    "        sequence_images = []\n",
    "\n",
    "        # Skip non-directory files\n",
    "        if not os.path.isdir(sequence_path):\n",
    "            continue\n",
    "        \n",
    "        allframes_path = sorted(os.listdir(sequence_path))\n",
    "\n",
    "        # Iterate through frames in the sequence\n",
    "        for i in trange(len(allframes_path),desc='Reading Images_'+sequence_folder):\n",
    "            frame_filename = allframes_path[i]\n",
    "\n",
    "            if not frame_filename.endswith('.png'):\n",
    "                continue\n",
    "\n",
    "            frame_path = os.path.join(sequence_path, frame_filename)\n",
    "\n",
    "            # Load the image\n",
    "            img = cv2.imread(frame_path)\n",
    "\n",
    "            # Append the image to the images list\n",
    "            sequence_images.append(img)\n",
    "            sleep(0.01)\n",
    "\n",
    "\n",
    "        preprocessing = preprocess(sequence_images, subject_folder, sequence_folder)\n",
    "        \n",
    "        '''\n",
    "        # Stack the image frames to create a sequence tensor\n",
    "        sequence_tensor = np.stack(preprocessing.tensor)\n",
    "\n",
    "        # Append the sequence tensor to the list of preprocessed images\n",
    "        preprocessed_images.append(sequence_tensor)\n",
    "\n",
    "        # Read the label for the current sequence from the Labels directory\n",
    "        label_file_path = os.path.join(labels_dir, subject_folder, sequence_folder + '.txt')\n",
    "        with open(label_file_path, 'r') as label_file:\n",
    "            sequence_label = int(float(label_file.read().strip()))\n",
    "\n",
    "        # Append the label to the list of preprocessed labels\n",
    "        preprocessed_labels.append(sequence_label)\n",
    "        '''\n",
    "        sleep(0.01)\n",
    "    sleep(0.01)\n",
    "\n",
    "        \n",
    "\n",
    "# Convert the lists of preprocessed images and labels to NumPy arrays\n",
    "preprocessed_images = np.array(preprocessed_images)\n",
    "preprocessed_labels = np.array(preprocessed_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tnrange, tqdm_notebook\n",
    "from time import sleep \n",
    "\n",
    "sequence_path = \"D:\\\\Library\\\\Documents\\\\UM Lecture Notes & Tutorial\\\\FYP\\\\Dataset\\\\UNBC-McMaster Shoulder Pain Data\\\\Images\\\\043-jh043\\\\jh043t1aeaff\"\n",
    "allframes_path = os.listdir(sequence_path)\n",
    "sequence_images=[]\n",
    "for i in tnrange(len(allframes_path),desc='progress'):\n",
    "    frame_filename = allframes_path[i]\n",
    "    frame_path = os.path.join(sequence_path, frame_filename)\n",
    "    # Load the image\n",
    "    img = cv2.imread(frame_path)\n",
    "    # Append the image to the images list\n",
    "    sequence_images.append(img)\n",
    "    sleep(0.01)\n",
    "\n",
    "print(len(sequence_images))\n",
    "preprocessing = preprocess(sequence_images, subject_folder, sequence_folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data and do subset for the data \n",
    "\n",
    "Select the frames from 48k images where consist of the PSPI from 0 to 10 (PSPI >10 is considered as 10) \n",
    "\n",
    "The data should be selected evenly from 25 subject, and each class should have 400 frames for each classes \n",
    "\n",
    "Total number of frames for each class\n",
    "{0: 40029, 1: 2909, 2: 2351, 4: 802, 5: 242, 6: 270, 3: 1412, 7: 53, 8: 79, 9: 32, 10: 67, 11: 76, 12: 48, 13: 22, 14: 1, 15: 5}\n",
    "\n",
    "There will be total of 4000 images consist in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 17, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0}\n",
      "continue\n",
      "{0: 34, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0}\n",
      "continue\n",
      "{0: 51, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0}\n",
      "continue\n",
      "{0: 68, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0}\n",
      "continue\n",
      "{0: 85, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0}\n",
      "continue\n",
      "{0: 102, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0}\n",
      "continue\n",
      "{0: 119, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0}\n",
      "continue\n",
      "{0: 136, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0}\n",
      "continue\n",
      "{0: 153, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0}\n",
      "continue\n",
      "{0: 170, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0}\n",
      "continue\n",
      "{0: 187, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0}\n",
      "continue\n",
      "{0: 204, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0}\n",
      "continue\n",
      "{0: 221, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0}\n",
      "continue\n",
      "{0: 238, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0}\n",
      "continue\n",
      "{0: 255, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0}\n",
      "continue\n",
      "{0: 272, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0}\n",
      "continue\n",
      "{0: 289, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0}\n",
      "continue\n",
      "{0: 306, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0}\n",
      "continue\n",
      "{0: 323, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0}\n",
      "continue\n",
      "{0: 340, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0}\n",
      "continue\n",
      "{0: 357, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0}\n",
      "continue\n",
      "{0: 374, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0}\n",
      "continue\n",
      "{0: 391, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0}\n",
      "continue\n",
      "{0: 408, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0}\n",
      "next\n",
      "{0: 408, 1: 17, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0}\n",
      "continue\n",
      "{0: 408, 1: 34, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0}\n",
      "continue\n",
      "{0: 408, 1: 51, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0}\n",
      "continue\n",
      "{0: 408, 1: 68, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0}\n",
      "continue\n",
      "{0: 408, 1: 101, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0}\n",
      "continue\n",
      "{0: 408, 1: 128, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0}\n",
      "continue\n",
      "{0: 408, 1: 145, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0}\n",
      "continue\n",
      "{0: 408, 1: 162, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0}\n",
      "continue\n",
      "{0: 408, 1: 179, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0}\n",
      "continue\n",
      "{0: 408, 1: 212, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0}\n",
      "continue\n",
      "{0: 408, 1: 229, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0}\n",
      "continue\n",
      "{0: 408, 1: 246, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0}\n",
      "continue\n",
      "{0: 408, 1: 263, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0}\n",
      "continue\n",
      "{0: 408, 1: 280, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0}\n",
      "continue\n",
      "{0: 408, 1: 297, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0}\n",
      "continue\n",
      "{0: 408, 1: 314, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0}\n",
      "continue\n",
      "{0: 408, 1: 331, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0}\n",
      "continue\n",
      "{0: 408, 1: 348, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0}\n",
      "continue\n",
      "{0: 408, 1: 365, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0}\n",
      "continue\n",
      "{0: 408, 1: 382, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0}\n",
      "continue\n",
      "{0: 408, 1: 399, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0}\n",
      "continue\n",
      "{0: 408, 1: 416, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0}\n",
      "next\n",
      "{0: 408, 1: 416, 2: 17, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0}\n",
      "continue\n",
      "{0: 408, 1: 416, 2: 34, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0}\n",
      "continue\n",
      "{0: 408, 1: 416, 2: 51, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0}\n",
      "continue\n",
      "{0: 408, 1: 416, 2: 73, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0}\n",
      "continue\n",
      "{0: 408, 1: 416, 2: 102, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0}\n",
      "continue\n",
      "{0: 408, 1: 416, 2: 119, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0}\n",
      "continue\n",
      "{0: 408, 1: 416, 2: 136, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0}\n",
      "continue\n",
      "{0: 408, 1: 416, 2: 153, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0}\n",
      "continue\n",
      "{0: 408, 1: 416, 2: 170, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0}\n",
      "continue\n",
      "{0: 408, 1: 416, 2: 187, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0}\n",
      "continue\n",
      "{0: 408, 1: 416, 2: 204, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0}\n",
      "continue\n",
      "{0: 408, 1: 416, 2: 221, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0}\n",
      "continue\n",
      "{0: 408, 1: 416, 2: 238, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0}\n",
      "continue\n",
      "{0: 408, 1: 416, 2: 257, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0}\n",
      "continue\n",
      "{0: 408, 1: 416, 2: 274, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0}\n",
      "continue\n",
      "{0: 408, 1: 416, 2: 291, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0}\n",
      "continue\n",
      "{0: 408, 1: 416, 2: 315, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0}\n",
      "continue\n",
      "{0: 408, 1: 416, 2: 332, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0}\n",
      "continue\n",
      "{0: 408, 1: 416, 2: 349, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0}\n",
      "continue\n",
      "{0: 408, 1: 416, 2: 366, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0}\n",
      "continue\n",
      "{0: 408, 1: 416, 2: 383, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0}\n",
      "continue\n",
      "{0: 408, 1: 416, 2: 400, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0}\n",
      "next\n",
      "{0: 408, 1: 416, 2: 400, 3: 17, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0}\n",
      "continue\n",
      "{0: 408, 1: 416, 2: 400, 3: 54, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0}\n",
      "continue\n",
      "{0: 408, 1: 416, 2: 400, 3: 80, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0}\n",
      "continue\n",
      "{0: 408, 1: 416, 2: 400, 3: 125, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0}\n",
      "continue\n",
      "{0: 408, 1: 416, 2: 400, 3: 142, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0}\n",
      "continue\n",
      "{0: 408, 1: 416, 2: 400, 3: 159, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0}\n",
      "continue\n",
      "{0: 408, 1: 416, 2: 400, 3: 176, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0}\n",
      "continue\n",
      "{0: 408, 1: 416, 2: 400, 3: 193, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0}\n",
      "continue\n",
      "{0: 408, 1: 416, 2: 400, 3: 224, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0}\n",
      "continue\n",
      "{0: 408, 1: 416, 2: 400, 3: 241, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0}\n",
      "continue\n",
      "{0: 408, 1: 416, 2: 400, 3: 258, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0}\n",
      "continue\n",
      "{0: 408, 1: 416, 2: 400, 3: 275, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0}\n",
      "continue\n",
      "{0: 408, 1: 416, 2: 400, 3: 292, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0}\n",
      "continue\n",
      "{0: 408, 1: 416, 2: 400, 3: 309, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0}\n",
      "continue\n",
      "{0: 408, 1: 416, 2: 400, 3: 332, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0}\n",
      "continue\n",
      "{0: 408, 1: 416, 2: 400, 3: 349, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0}\n",
      "continue\n",
      "{0: 408, 1: 416, 2: 400, 3: 366, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0}\n",
      "continue\n",
      "{0: 408, 1: 416, 2: 400, 3: 383, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0}\n",
      "continue\n",
      "{0: 408, 1: 416, 2: 400, 3: 400, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0}\n",
      "next\n",
      "{0: 408, 1: 416, 2: 400, 3: 400, 4: 17, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0}\n",
      "continue\n",
      "{0: 408, 1: 416, 2: 400, 3: 400, 4: 34, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0}\n",
      "continue\n",
      "{0: 408, 1: 416, 2: 400, 3: 400, 4: 51, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0}\n",
      "continue\n",
      "{0: 408, 1: 416, 2: 400, 3: 400, 4: 69, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0}\n",
      "continue\n",
      "{0: 408, 1: 416, 2: 400, 3: 400, 4: 91, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0}\n",
      "continue\n",
      "{0: 408, 1: 416, 2: 400, 3: 400, 4: 108, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0}\n",
      "continue\n",
      "{0: 408, 1: 416, 2: 400, 3: 400, 4: 129, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0}\n",
      "continue\n",
      "{0: 408, 1: 416, 2: 400, 3: 400, 4: 159, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0}\n",
      "continue\n",
      "{0: 408, 1: 416, 2: 400, 3: 400, 4: 178, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0}\n",
      "continue\n",
      "{0: 408, 1: 416, 2: 400, 3: 400, 4: 200, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0}\n",
      "continue\n",
      "{0: 408, 1: 416, 2: 400, 3: 400, 4: 217, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0}\n",
      "continue\n",
      "{0: 408, 1: 416, 2: 400, 3: 400, 4: 234, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0}\n",
      "continue\n",
      "{0: 408, 1: 416, 2: 400, 3: 400, 4: 265, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0}\n",
      "continue\n",
      "{0: 408, 1: 416, 2: 400, 3: 400, 4: 282, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0}\n",
      "continue\n",
      "{0: 408, 1: 416, 2: 400, 3: 400, 4: 299, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0}\n",
      "continue\n",
      "{0: 408, 1: 416, 2: 400, 3: 400, 4: 326, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0}\n",
      "continue\n",
      "{0: 408, 1: 416, 2: 400, 3: 400, 4: 343, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0}\n",
      "continue\n",
      "{0: 408, 1: 416, 2: 400, 3: 400, 4: 360, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0}\n",
      "continue\n",
      "{0: 408, 1: 416, 2: 400, 3: 400, 4: 377, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0}\n",
      "continue\n",
      "{0: 408, 1: 416, 2: 400, 3: 400, 4: 394, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0}\n",
      "continue\n",
      "{0: 408, 1: 416, 2: 400, 3: 400, 4: 411, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0}\n",
      "next\n",
      "{0: 408, 1: 416, 2: 400, 3: 400, 4: 411, 5: 35, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0}\n",
      "continue\n",
      "{0: 408, 1: 416, 2: 400, 3: 400, 4: 411, 5: 66, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0}\n",
      "continue\n",
      "{0: 408, 1: 416, 2: 400, 3: 400, 4: 411, 5: 92, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0}\n",
      "continue\n",
      "{0: 408, 1: 416, 2: 400, 3: 400, 4: 411, 5: 122, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0}\n",
      "continue\n",
      "{0: 408, 1: 416, 2: 400, 3: 400, 4: 411, 5: 139, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0}\n",
      "continue\n",
      "{0: 408, 1: 416, 2: 400, 3: 400, 4: 411, 5: 156, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0}\n",
      "continue\n",
      "{0: 408, 1: 416, 2: 400, 3: 400, 4: 411, 5: 183, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0}\n",
      "continue\n",
      "{0: 408, 1: 416, 2: 400, 3: 400, 4: 411, 5: 200, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0}\n",
      "continue\n",
      "{0: 408, 1: 416, 2: 400, 3: 400, 4: 411, 5: 235, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0}\n",
      "continue\n",
      "{0: 408, 1: 416, 2: 400, 3: 400, 4: 411, 5: 242, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0}\n",
      "continue\n",
      "{0: 408, 1: 416, 2: 400, 3: 400, 4: 411, 5: 242, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0}\n",
      "next\n",
      "{0: 408, 1: 416, 2: 400, 3: 400, 4: 411, 5: 242, 6: 39, 7: 0, 8: 0, 9: 0, 10: 0}\n",
      "continue\n",
      "{0: 408, 1: 416, 2: 400, 3: 400, 4: 411, 5: 242, 6: 65, 7: 0, 8: 0, 9: 0, 10: 0}\n",
      "continue\n",
      "{0: 408, 1: 416, 2: 400, 3: 400, 4: 411, 5: 242, 6: 82, 7: 0, 8: 0, 9: 0, 10: 0}\n",
      "continue\n",
      "{0: 408, 1: 416, 2: 400, 3: 400, 4: 411, 5: 242, 6: 99, 7: 0, 8: 0, 9: 0, 10: 0}\n",
      "continue\n",
      "{0: 408, 1: 416, 2: 400, 3: 400, 4: 411, 5: 242, 6: 116, 7: 0, 8: 0, 9: 0, 10: 0}\n",
      "continue\n",
      "{0: 408, 1: 416, 2: 400, 3: 400, 4: 411, 5: 242, 6: 133, 7: 0, 8: 0, 9: 0, 10: 0}\n",
      "continue\n",
      "{0: 408, 1: 416, 2: 400, 3: 400, 4: 411, 5: 242, 6: 150, 7: 0, 8: 0, 9: 0, 10: 0}\n",
      "continue\n",
      "{0: 408, 1: 416, 2: 400, 3: 400, 4: 411, 5: 242, 6: 169, 7: 0, 8: 0, 9: 0, 10: 0}\n",
      "continue\n",
      "{0: 408, 1: 416, 2: 400, 3: 400, 4: 411, 5: 242, 6: 206, 7: 0, 8: 0, 9: 0, 10: 0}\n",
      "continue\n",
      "{0: 408, 1: 416, 2: 400, 3: 400, 4: 411, 5: 242, 6: 223, 7: 0, 8: 0, 9: 0, 10: 0}\n",
      "continue\n",
      "{0: 408, 1: 416, 2: 400, 3: 400, 4: 411, 5: 242, 6: 241, 7: 0, 8: 0, 9: 0, 10: 0}\n",
      "continue\n",
      "{0: 408, 1: 416, 2: 400, 3: 400, 4: 411, 5: 242, 6: 258, 7: 0, 8: 0, 9: 0, 10: 0}\n",
      "continue\n",
      "{0: 408, 1: 416, 2: 400, 3: 400, 4: 411, 5: 242, 6: 270, 7: 0, 8: 0, 9: 0, 10: 0}\n",
      "continue\n",
      "{0: 408, 1: 416, 2: 400, 3: 400, 4: 411, 5: 242, 6: 270, 7: 0, 8: 0, 9: 0, 10: 0}\n",
      "next\n",
      "{0: 408, 1: 416, 2: 400, 3: 400, 4: 411, 5: 242, 6: 270, 7: 53, 8: 0, 9: 0, 10: 0}\n",
      "continue\n",
      "{0: 408, 1: 416, 2: 400, 3: 400, 4: 411, 5: 242, 6: 270, 7: 53, 8: 0, 9: 0, 10: 0}\n",
      "next\n",
      "{0: 408, 1: 416, 2: 400, 3: 400, 4: 411, 5: 242, 6: 270, 7: 53, 8: 20, 9: 0, 10: 0}\n",
      "continue\n",
      "{0: 408, 1: 416, 2: 400, 3: 400, 4: 411, 5: 242, 6: 270, 7: 53, 8: 41, 9: 0, 10: 0}\n",
      "continue\n",
      "{0: 408, 1: 416, 2: 400, 3: 400, 4: 411, 5: 242, 6: 270, 7: 53, 8: 70, 9: 0, 10: 0}\n",
      "continue\n",
      "{0: 408, 1: 416, 2: 400, 3: 400, 4: 411, 5: 242, 6: 270, 7: 53, 8: 79, 9: 0, 10: 0}\n",
      "continue\n",
      "{0: 408, 1: 416, 2: 400, 3: 400, 4: 411, 5: 242, 6: 270, 7: 53, 8: 79, 9: 0, 10: 0}\n",
      "next\n",
      "{0: 408, 1: 416, 2: 400, 3: 400, 4: 411, 5: 242, 6: 270, 7: 53, 8: 79, 9: 32, 10: 0}\n",
      "continue\n",
      "{0: 408, 1: 416, 2: 400, 3: 400, 4: 411, 5: 242, 6: 270, 7: 53, 8: 79, 9: 32, 10: 0}\n",
      "next\n",
      "{0: 408, 1: 416, 2: 400, 3: 400, 4: 411, 5: 242, 6: 270, 7: 53, 8: 79, 9: 32, 10: 20}\n",
      "continue\n",
      "{0: 408, 1: 416, 2: 400, 3: 400, 4: 411, 5: 242, 6: 270, 7: 53, 8: 79, 9: 32, 10: 37}\n",
      "continue\n",
      "{0: 408, 1: 416, 2: 400, 3: 400, 4: 411, 5: 242, 6: 270, 7: 53, 8: 79, 9: 32, 10: 67}\n",
      "continue\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\Library\\Documents\\UM Lecture Notes & Tutorial\\FYP\\Source Code\\Execute\\modeltraining.ipynb Cell 18\u001b[0m line \u001b[0;36m<cell line: 14>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Library/Documents/UM%20Lecture%20Notes%20%26%20Tutorial/FYP/Source%20Code/Execute/modeltraining.ipynb#X23sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39mif\u001b[39;00m i\u001b[39m<\u001b[39m\u001b[39m=\u001b[39m\u001b[39m16\u001b[39m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Library/Documents/UM%20Lecture%20Notes%20%26%20Tutorial/FYP/Source%20Code/Execute/modeltraining.ipynb#X23sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m \tpain_intensity \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Library/Documents/UM%20Lecture%20Notes%20%26%20Tutorial/FYP/Source%20Code/Execute/modeltraining.ipynb#X23sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \t\u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(PSPI_sequence_id_folder, frames), \u001b[39m'\u001b[39;49m\u001b[39mr\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m label_file:\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Library/Documents/UM%20Lecture%20Notes%20%26%20Tutorial/FYP/Source%20Code/Execute/modeltraining.ipynb#X23sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \t\tpain_intensity \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(\u001b[39mfloat\u001b[39m(label_file\u001b[39m.\u001b[39mread()\u001b[39m.\u001b[39mstrip()))\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Library/Documents/UM%20Lecture%20Notes%20%26%20Tutorial/FYP/Source%20Code/Execute/modeltraining.ipynb#X23sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m \tappend_flag \u001b[39m=\u001b[39m read_file\u001b[39m.\u001b[39mget(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(PSPI_sequence_id_folder, frames))\n",
      "File \u001b[1;32mc:\\Users\\xiao cheng\\AppData\\Local\\Programs\\Python\\Python310\\lib\\codecs.py:309\u001b[0m, in \u001b[0;36mBufferedIncrementalDecoder.__init__\u001b[1;34m(self, errors)\u001b[0m\n\u001b[0;32m    303\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mBufferedIncrementalDecoder\u001b[39;00m(IncrementalDecoder):\n\u001b[0;32m    304\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    305\u001b[0m \u001b[39m    This subclass of IncrementalDecoder can be used as the baseclass for an\u001b[39;00m\n\u001b[0;32m    306\u001b[0m \u001b[39m    incremental decoder if the decoder must be able to handle incomplete\u001b[39;00m\n\u001b[0;32m    307\u001b[0m \u001b[39m    byte sequences.\u001b[39;00m\n\u001b[0;32m    308\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 309\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, errors\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mstrict\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m    310\u001b[0m         IncrementalDecoder\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, errors)\n\u001b[0;32m    311\u001b[0m         \u001b[39m# undecoded input that is kept between calls to decode()\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from time import sleep\n",
    "from tqdm.notebook import trange\n",
    "import os \n",
    "subset_image_dir = {}\n",
    "subset_label= {}\n",
    "class_count = {x:0 for x in range(11)}\n",
    "read_file = {}\n",
    "\n",
    "dataset_root = \"D:\\\\Library\\Documents\\\\UM Lecture Notes & Tutorial\\\\FYP\\\\Dataset\\\\UNBC-McMaster Shoulder Pain Data\"\n",
    "img_folder_dir = os.path.join(dataset_root, \"Images\")\n",
    "PSPI_folder_dir = os.path.join(dataset_root, \"Frame_Labels\", \"PSPI\")\n",
    "subject_id = os.listdir(img_folder_dir)\n",
    "PSPI_score = 0\n",
    "while True:\n",
    "\tcount = class_count.get(PSPI_score)\n",
    "\tfor subject in subject_id:\n",
    "\t\ttemp = {}\n",
    "\t\tPSPI_sequence_dir = os.path.join(PSPI_folder_dir, subject)\n",
    "\t\ti = 0\n",
    "\t\tfor sequence_id in os.listdir(PSPI_sequence_dir):\n",
    "\t\t\tPSPI_sequence_id_folder = os.path.join(PSPI_sequence_dir, sequence_id)\n",
    "\t\t\ttemp_img_dir_list =[]\n",
    "\t\t\ttemp_label_list = []\n",
    "\t\t\tfor frames in os.listdir(PSPI_sequence_id_folder):\n",
    "\t\t\t\tif i<=16:\n",
    "\t\t\t\t\tpain_intensity = 0\n",
    "\t\t\t\t\twith open(os.path.join(PSPI_sequence_id_folder, frames), 'r') as label_file:\n",
    "\t\t\t\t\t\tpain_intensity = int(float(label_file.read().strip()))\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\tappend_flag = read_file.get(os.path.join(PSPI_sequence_id_folder, frames))\n",
    "\t\t\t\t\tif pain_intensity == PSPI_score and append_flag is None:\n",
    "\t\t\t\t\t\ttemp_img_dir_list.append(os.path.join(img_folder_dir,subject, sequence_id, frames))\n",
    "\t\t\t\t\t\ttemp_label_list.append(os.path.join(PSPI_sequence_id_folder, frames))\n",
    "\t\t\t\t\t\tread_file[os.path.join(PSPI_sequence_id_folder, frames)] = False\n",
    "\t\t\t\t\t\ti+=1\n",
    "\t\t\t\t\t\tcount+=1\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tbreak\n",
    "\t\t\tif subset_image_dir.get(subject) is None:\n",
    "\t\t\t\tsubset_image_dir[subject] = temp_img_dir_list\n",
    "\t\t\t\tsubset_label[subject] = temp_label_list\n",
    "\t\t\telse:\n",
    "\t\t\t\tupdate_img_list = subset_image_dir.get(subject)\n",
    "\t\t\t\tupdate_img_list.extend(temp_img_dir_list)\n",
    "\t\t\t\tsubset_image_dir.update({subject:(update_img_list)})\n",
    "\n",
    "\t\t\t\tupdate_label_list = subset_label.get(subject)\n",
    "\t\t\t\tupdate_label_list.extend(temp_label_list)\n",
    "\t\t\t\tsubset_label.update({subject:(update_label_list)})\n",
    "\t\t\tif i == 17:\n",
    "\t\t\t\tbreak\n",
    "\t\tif i ==17:\n",
    "\t\t\tbreak\n",
    "\n",
    "\tif count<400 and not count==class_count.get(PSPI_score):\n",
    "\t\tclass_count.update({PSPI_score:count})\n",
    "\t\tprint(class_count)\n",
    "\t\tprint(\"continue\")\n",
    "\t\tcontinue\n",
    "\telif PSPI_score < 14 :\n",
    "\t\tclass_count.update({PSPI_score:count})\n",
    "\t\tprint(class_count)\n",
    "\t\tprint(\"next\")\n",
    "\t\tPSPI_score+=1\n",
    "\telse:\n",
    "\t\tbreak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import cv2\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from torchvision import transforms\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from tqdm import tnrange, tqdm_notebook\n",
    "from time import sleep\n",
    "\n",
    "\n",
    "def load_subject_data(subject_name):\n",
    "    subject_dir = os.path.join(\"/content/drive/MyDrive/Colab Notebooks/Dataset/Preprocessed\",subject_name)\n",
    "    frames = []  # Load frames from the subject's directory\n",
    "    pain_intensity_labels = []  # Load corresponding labels\n",
    "    all_subject_sequence = sorted(os.listdir(subject_dir))\n",
    "    for i in trange(len(all_subject_sequence),desc='Subject level progress'):\n",
    "        sequence = all_subject_sequence[i]\n",
    "        sequence_dir = os.path.join(subject_dir,sequence)\n",
    "        allframes_ofsequence = os.listdir(sequence_dir)\n",
    "        for n in trange(len(allframes_ofsequence),desc= (sequence + ' - Sequence level progress')):\n",
    "            filename = allframes_ofsequence[n]\n",
    "            if filename.endswith(\".png\"):\n",
    "                try:\n",
    "                    # Load the pain intensity label from the corresponding text file\n",
    "                    label_filename = os.path.splitext(filename)[0] + '_facs.txt'\n",
    "                    label_path = os.path.join(\"/content/drive/MyDrive/Colab Notebooks/Dataset/Frame_Labels/PSPI\", subject_name, sequence)\n",
    "                    with open(os.path.join(label_path, label_filename), 'r') as label_file:\n",
    "                        pain_intensity = int(float(label_file.read().strip()))\n",
    "                        pain_intensity_labels.append(pain_intensity)\n",
    "\n",
    "                    # Load the image\n",
    "                    img = cv2.imread(os.path.join(sequence_dir, filename))\n",
    "                    img = cv2.resize(img, (120,120))\n",
    "                    frames.append(img)\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "                finally:\n",
    "                    sleep(0.01)\n",
    "                    continue\n",
    "                \n",
    "        sleep(0.01)\n",
    "\n",
    "\n",
    "    return frames, pain_intensity_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom dataset\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, root_dir):\n",
    "        self.root_dir = root_dir\n",
    "        self.image_dir = os.path.join(root_dir,\"Images\")\n",
    "        self.subjects = os.listdir(self.image_dir)\n",
    "        self.transform = transforms.Compose([])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.subjects)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        subject = self.subjects[idx]\n",
    "\n",
    "        frames, labels = load_subject_data(subject) # Load labels from labels_path\n",
    "\n",
    "        frames = self.transform(frames)\n",
    "\n",
    "        return frames, labels\n",
    "\n",
    "# Define a simple CNN model\n",
    "class PainScorePredictor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PainScorePredictor, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.fc1 = nn.Linear(64 * 120 * 120 // 4, 128)\n",
    "        self.fc2 = nn.Linear(128, 1)  # Assuming pain score is a scalar value\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(nn.functional.F.relu(self.conv1(x)))\n",
    "        x = self.pool(nn.functional.F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 64 * 120 * 120 // 4)\n",
    "        x = nn.functional.F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Assuming your dataset is structured as described, with an \"images\" folder and a \"labels\" folder\n",
    "dataset = CustomDataset(root_dir='/content/drive/MyDrive/Colab Notebooks/Dataset')\n",
    "\n",
    "# Set device to CUDA if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "num_epochs = 10\n",
    "\n",
    "# Step 1: Group K-Fold Cross-Validation\n",
    "gkf = GroupKFold(n_splits=25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fold, (train_idx, val_idx) in enumerate(gkf.split(dataset, y=None, groups=dataset.subjects)):\n",
    "\n",
    "    model = PainScorePredictor().to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    train_dataset = torch.utils.data.Subset(dataset, train_idx)\n",
    "    val_dataset = torch.utils.data.Subset(dataset, val_idx)\n",
    "\n",
    "     # Set up DataLoader for training and validation\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4)\n",
    "    print(train_dataset)\n",
    "    print(train_idx)\n",
    "    print(val_dataset)\n",
    "    print(val_idx)\n",
    "\n",
    "    # Step 2: Compute Class Weights\n",
    "    train_labels = [label for _, labels in train_dataset for label in labels]\n",
    "    class_weights = compute_class_weight('balanced', classes=torch.unique(train_labels), y=train_labels)\n",
    "    class_weight_dict = dict(zip(torch.unique(train_labels), class_weights))\n",
    "\n",
    "    # Step 3: Resample with SMOTE (or other methods) using class weights\n",
    "    smote = SMOTE(random_state=42)\n",
    "\n",
    "    # Step 4: Train your model with class weights\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "\n",
    "    # Assuming you have a DataLoader for training\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=10, shuffle=True)\n",
    "\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for inputs, labels in train_dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            # Resample using SMOTE and class weights\n",
    "            inputs, labels = smote.fit_resample(torch.stack(inputs).reshape(-1, (120*120*3)), labels)\n",
    "            inputs = inputs.reshape(-1, len(inputs), (120*120*3))\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(*inputs)\n",
    "\n",
    "            # Compute loss\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "\n",
    "            # Optimizer step\n",
    "            optimizer.step()\n",
    "\n",
    "        # Validation loop\n",
    "        model.eval()\n",
    "        total_loss = 0.0\n",
    "        correct_predictions = 0\n",
    "        total_samples = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_dataloader:\n",
    "                inputs = [frame.to(device) for frame in inputs]\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # Forward pass\n",
    "                outputs = model(*inputs)\n",
    "\n",
    "                # Compute loss\n",
    "                loss = criterion(outputs, labels)\n",
    "                total_loss += loss.item()\n",
    "\n",
    "                # Compute accuracy (or other metrics)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                correct_predictions += (predicted == labels).sum().item()\n",
    "                total_samples += labels.size(0)\n",
    "\n",
    "        # Calculate metrics\n",
    "        average_loss = total_loss / len(val_dataloader)\n",
    "        accuracy = correct_predictions / total_samples\n",
    "\n",
    "        # Print or log metrics\n",
    "        print(f'Epoch {epoch + 1}/{num_epochs}, Validation Loss: {average_loss:.4f}, Accuracy: {accuracy * 100:.2f}%')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
